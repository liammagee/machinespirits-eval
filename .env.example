# Machinespirits Eval - Environment Configuration
# Copy this file to .env and fill in your API keys

# ====================
# AI Provider API Keys
# ====================

# OpenRouter (required for ego/superego model access — Kimi K2.5, Nemotron, etc.)
OPENROUTER_API_KEY=

# Anthropic (required for Claude-based judging via the Anthropic SDK)
ANTHROPIC_API_KEY=

# OpenAI (optional — for GPT-based cross-judge validation)
OPENAI_API_KEY=

# Google Gemini (optional)
GEMINI_API_KEY=

# ====================
# Eval Overrides (all optional)
# ====================

# Override content package path (default: ./content-test-elementary)
# Point to a full content package for production evaluations
# EVAL_CONTENT_PATH=../machinespirits-content-philosophy

# Override scenarios file (for domain generalizability testing)
# EVAL_SCENARIOS_FILE=content-test-elementary/scenarios-elementary.yaml

# Override database path (default: data/evaluations.db)
# EVAL_DB_PATH=data/evaluations.db

# ====================
# Server (optional — only needed for `npm start`)
# ====================

# PORT=8081

# ====================
# Debug
# ====================

# Clean transcript output (suppresses debug logs)
# TUTOR_TRANSCRIPT=true

# Verbose learner simulation logging
# LEARNER_DEBUG=true
