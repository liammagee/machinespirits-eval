# Machinespirits Eval - Environment Configuration
# Copy this file to .env and fill in your API keys

# ====================
# AI Provider API Keys
# ====================

# OpenRouter (required for ego/superego model access — Kimi K2.5, Nemotron, etc.)
OPENROUTER_API_KEY=

# Anthropic (required if using Claude as judge via the Anthropic SDK)
ANTHROPIC_API_KEY=

# OpenAI (optional — used for GPT-based cross-judge validation)
OPENAI_API_KEY=

# Google Gemini (optional)
GEMINI_API_KEY=

# Groq (optional — fast inference for lighter models)
GROQ_API_KEY=

# ====================
# Provider Configuration
# ====================

# Which provider to use by default for ego/superego generation
DEFAULT_AI_PROVIDER=openrouter

# Override default models per provider (optional)
# OPENROUTER_MODEL=moonshotai/kimi-k2.5
# OPENAI_MODEL=gpt-5.2
# ANTHROPIC_MODEL=claude-opus-4-5-20251101
# GROQ_MODEL=llama-3.1-8b-instant

# ====================
# AI Response Settings
# ====================

# AI_TEMPERATURE=1.0       # Creativity level (0.0 - 2.0)
# AI_MAX_TOKENS=2000       # Maximum response length

# ====================
# Application Settings
# ====================

# Server port (for standalone mode)
PORT=8081
STANDALONE=true

# NODE_ENV=development
# LOG_LEVEL=info

# Learner simulation profile (optional)
# LEARNER_PROFILE=default

# Set to 'true' for clean transcript output (suppresses debug logs)
# TUTOR_TRANSCRIPT=true
